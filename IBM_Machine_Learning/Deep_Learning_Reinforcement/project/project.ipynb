{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a8f6d4-e7b3-4ce4-9dd6-f27660f280f1",
   "metadata": {},
   "source": [
    "## COVID-19 X-ray Classification\n",
    "\n",
    "### <ins>1. Objective</ins>\n",
    "#### Coronavirus disease (COVID-19) is an respiratory infectious disease caused by the SARS-CoV-2 virus.\n",
    "#### Chest x-rays can be used in diagnosis and follow up in patients with COVID-19 pneumonia. Given the strain on the medical staff, automatic diagnosis of COVID-19 from chest x-ray can free up personnel needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7b3e41-a55a-4a0c-a908-4819fa0f5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import applications, Model, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e3b2a-a2c9-47fb-a3e8-8933d5568884",
   "metadata": {},
   "source": [
    "### <ins>2. Data</ins>\n",
    "#### Data is from https://www.kaggle.com/datasets/masumrefat/chest-xray-images-pneumonia-and-covid19\n",
    "\n",
    "#### Data consists of axial, coronal and saggital views of the chest for the following 3 classifications as determined by radiologists\n",
    "1. COVID-19 positive\n",
    "<img src=\"./Chest_xray_image_dataset_covid_19_and_others/train/Covid_19/1.CXRCTThoraximagesofCOVID-19fromSingapore.pdf-000-fig1a.png\" alt=\"covid\" width=\"200\"/>\n",
    "\n",
    "2. Normal\n",
    "<img src=\"./Chest_xray_image_dataset_covid_19_and_others/train/NORMAL/IM-0001-0001.jpeg\" alt=\"covid\" width=\"200\"/>\n",
    "\n",
    "3. Pneumonia (COVID-19 negative)\n",
    "<img src=\"./Chest_xray_image_dataset_covid_19_and_others/train/PNEUMONIA/person1_bacteria_1.jpeg\" alt=\"covid\" width=\"200\"/>\n",
    "\n",
    "#### Approach\n",
    "Use Deep Learning to classify chest x-rays into Covid-19, normal and pneumonia (Covid-19 negative). 3 models used includes,\n",
    "1. VGG16 type model\n",
    "2. Transfer learning with ResNet\n",
    "3. Hyperparameter tuned transfer learning with ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3279b7-1e19-4dc9-8fd1-1cbe39b5952a",
   "metadata": {},
   "source": [
    "### <ins>3. Data Exploration</ins>\n",
    "Find the largest and smallest image size from the training set. This will be used to determine an appropriate image size used for training and prediction. Too big and training will take a long time requiring lots of memory. Too small and critical information will be lost in resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae9a8f-2a12-4caa-98fe-7b63847396b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect images from each path in training set\n",
    "train_data_dir = \"./Chest_xray_image_dataset_covid_19_and_others/train\"\n",
    "\n",
    "train_covid_images = [os.path.join(train_data_dir, 'Covid_19', image) for image in os.listdir(os.path.join(train_data_dir, 'Covid_19'))]\n",
    "train_normal_images = [os.path.join(train_data_dir, 'NORMAL', image) for image in os.listdir(os.path.join(train_data_dir, 'NORMAL'))]\n",
    "train_pneumonia_images = [os.path.join(train_data_dir, 'PNEUMONIA', image) for image in os.listdir(os.path.join(train_data_dir, 'PNEUMONIA'))]\n",
    "\n",
    "print(\"Number of Covid_19 images in training dataset, \", len(train_covid_images))\n",
    "print(\"Number of Normal images in training dataset, \", len(train_normal_images))\n",
    "print(\"Number of Pneumonia images in training dataset, \", len(train_pneumonia_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab51e4d-ab6d-4f2b-b084-50da4dbf72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of image sizes\n",
    "image_size_list = list()\n",
    "for image_path in train_covid_images+train_normal_images+train_pneumonia_images:\n",
    "    image_size_list.append(Image.open(image_path).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91b5d0-d1fe-413f-a1e7-45d5bdeb7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find largest and smallest image size in training set\n",
    "largest_image_size = list(map(max, zip(*image_size_list)))\n",
    "smallest_image_size = list(map(min, zip(*image_size_list)))\n",
    "  \n",
    "print (\"Largest image size in training set, \", largest_image_size)\n",
    "print (\"Smallest image size in training set. \", smallest_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82fdf13-ae0c-4cc0-b360-40ef686a6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign image size used for training prediction.\n",
    "image_width = 224\n",
    "image_height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76451ef-f027-48fc-bcda-f4a38fa9042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect images from each path in testing set\n",
    "test_data_dir = \"./Chest_xray_image_dataset_covid_19_and_others/test\"\n",
    "\n",
    "test_covid_images = [os.path.join(test_data_dir, 'Covid_19', image) for image in os.listdir(os.path.join(test_data_dir, 'Covid_19'))]\n",
    "test_normal_images = [os.path.join(test_data_dir, 'NORMAL', image) for image in os.listdir(os.path.join(test_data_dir, 'NORMAL'))]\n",
    "test_pneumonia_images = [os.path.join(test_data_dir, 'PNEUMONIA', image) for image in os.listdir(os.path.join(test_data_dir, 'PNEUMONIA'))]\n",
    "\n",
    "print(\"Number of Covid_19 images in testing dataset, \", len(test_covid_images))\n",
    "print(\"Number of Normal images in testing dataset, \", len(test_normal_images))\n",
    "print(\"Number of Pneumonia images in testing dataset, \", len(test_pneumonia_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b674f75-c054-4bc3-8f26-2e2658fb5025",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "To minimize overfit, augment the training image data with\n",
    "1. rescale pixels to range from 0 to 1\n",
    "2. shear by 0.2\n",
    "3. zoom by 0.2\n",
    "4. shift by width by 0.2\n",
    "5. shift by height by 0.2\n",
    "6. horizontal flip\n",
    "\n",
    "For test image dataset, only rescaling is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923ce123-c4ce-468f-b442-72d3c69f35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image data generator for augmentation\n",
    "train_data_generator = ImageDataGenerator(rescale=1. / 255, \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dcdbe-2d8b-4796-86b9-5522c50a743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create augmented images with resizing to assigned image width, height\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = train_data_generator.flow_from_directory(train_data_dir, target_size=(image_height, image_width), batch_size=batch_size, class_mode='categorical')\n",
    "test_dataset = test_data_generator.flow_from_directory(test_data_dir, target_size=(image_height, image_width), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022319c-4f6a-4da6-9978-783724a699de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample augmented and resized output\n",
    "x, y = next(train_dataset)\n",
    "print(\"Batch size, image height, image width, number of classes\", x.shape)\n",
    "print(\"\\ny consists of the one-hot encoding of the 3 classes for 1 batch of 8 images\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c135ac7-baf6-4304-95a0-7d1f608f868a",
   "metadata": {},
   "source": [
    "### <ins>4. Deep Learning Modeling</ins>\n",
    "\n",
    "1. VGG16 type model\n",
    "2. Transfer learning with ResNet\n",
    "3. Hyperparameter tuned transfer learning with ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f16b7f-b4c1-4bff-a9ba-61858df83380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    precision = precision_metric(y_true, y_pred)\n",
    "    recall = recall_metric(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a300b55-724e-4ddd-a7e5-784b6185cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss, accuracy, f1\n",
    "def plot_results(model_history):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(model_history.history['loss'], label='train loss')\n",
    "    plt.plot(model_history.history['val_loss'], label='val loss')\n",
    "    plt.title('Epoch vs loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(model_history.history['accuracy'], label='train accuracy')\n",
    "    plt.plot(model_history.history['val_accuracy'], label='val accuracy')\n",
    "    plt.title('Epoch vs accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(model_history.history['f1_metric'], label='train f1')\n",
    "    plt.plot(model_history.history['val_f1_metric'], label='val f1')\n",
    "    plt.title('Epoch vs F1')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ca0c-585b-42ec-9f46-510fbe22fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification\n",
    "def make_predictions(test_dataset, model):\n",
    "    all_predicts = list()\n",
    "    all_truths = list()\n",
    "    for test_batch_image, test_batch_class in tqdm(test_dataset, disable=True):\n",
    "        predict_class = model.predict(test_batch_image)\n",
    "        predict_class = np.argmax(predict_class, 1)\n",
    "        all_predicts.extend(list(predict_class))\n",
    "        all_truths.extend(list(np.argmax(test_batch_class, 1)))\n",
    "    \n",
    "    print(classification_report(all_truths, all_predicts))\n",
    "    return all_predicts, all_truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72bf1b9-f03e-4f54-b48e-b0f87cb7d430",
   "metadata": {},
   "source": [
    "#### 4.1. VGG16\n",
    "- Optimizer = 'adam'\n",
    "- Loss = 'categorical_crossentropy'\n",
    "- Metrics = 'accuracy', 'f1'\n",
    "\n",
    "F1 score evaluated due to the imbalance of dataset. There are much fewer Covid_19 positive x-rays than normal than pneumonia, which could skew the predictions. F1 score balances the precision and recall for a better evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6937db-9f2e-47a5-a3d5-170a3cf75900",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model = Sequential([\n",
    "            Conv2D(32,(3,3),strides=(1, 1),activation='relu',padding='same', input_shape=(image_height, image_width, 3)), \n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Conv2D(64,(3,3),strides=(1, 1) ,padding='same',activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Conv2D(128,(3,3),strides=(1, 1),padding='same', activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Conv2D(256,(3,3),strides=(1, 1),padding='same', activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c2b60-2994-48c9-89e7-6e399ad90d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "VGG_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', f1_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f857c4-74a9-4da7-913e-d9778935fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "VGG_model_fit = VGG_model.fit(train_dataset,\n",
    "                              epochs = 1,\n",
    "                              validation_data = test_dataset,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83e859-0e37-4ec8-9441-a0a19b1fae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training\n",
    "plot_results(VGG_model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd44421-4333-4884-9424-7d524bc37edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "make_predictions(test_dataset, VGG_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14fe16-9ec5-426e-942f-63f58e466367",
   "metadata": {},
   "source": [
    "#### 4.2. Transfer learning with ResNet\n",
    "- Optimizer = 'adam'\n",
    "- Loss = 'categorical_crossentropy'\n",
    "- Metrics = 'accuracy', 'f1'\n",
    "\n",
    "F1 score evaluated due to the imbalance of dataset. There are much fewer Covid_19 positive x-rays than normal than pneumonia, which could skew the predictions. F1 score balances the precision and recall for a better evaluation metric.\n",
    "\n",
    "Last layer of resnet removed and the training image set fed in for transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e68661-751a-40ce-add3-1ff374c77fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet\n",
    "transfer_resnet_model = applications.resnet.ResNet50(weights='imagenet', \n",
    "                                                     include_top=False)\n",
    "global_avg_pooling = GlobalAveragePooling2D()(transfer_resnet_model.output)\n",
    "output = Dense(3, activation='softmax')(global_avg_pooling)\n",
    "resnet_model = Model(inputs=transfer_resnet_model.input, \n",
    "                     outputs=output)\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "resnet_model.compile(loss='categorical_crossentropy', \n",
    "                     optimizer=optimizer, \n",
    "                     metrics=['accuracy', f1_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b720d-ce3d-4505-8c3d-fea050703801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "resnet_model_fit = resnet_model.fit(train_dataset, \n",
    "                                    epochs=1, \n",
    "                                    validation_data=test_dataset, \n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898035c4-a88e-4917-8f04-5be6ea55b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training\n",
    "plot_results(resnet_model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873479e8-b2cd-45ec-8cf7-dabf7476aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "make_predictions(test_dataset, resnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b0e40-8437-4a0b-a5b7-72e07da2e1d5",
   "metadata": {},
   "source": [
    "#### 4.3. Hyperparameter Tune Transfer learning with ResNet\n",
    "- Optimizer = 'adam'\n",
    "- Loss = 'categorical_crossentropy'\n",
    "- Metrics = 'accuracy', 'f1'\n",
    "- Dropout = 0.5\n",
    "\n",
    "Dropouts added to reduce overfitting.\n",
    "\n",
    "F1 score evaluated due to the imbalance of dataset. There are much fewer Covid_19 positive x-rays than normal than pneumonia, which could skew the predictions. F1 score balances the precision and recall for a better evaluation metric.\n",
    "\n",
    "Last layer of resnet removed and the training image set fed in for transfer learning.\n",
    "\n",
    "Callback added for earlystopping when minimum val_loss is reached and best model based on val_loss is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23431a-205b-4c07-b19b-73edb53a9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet\n",
    "transfer_resnet_model = applications.resnet.ResNet50(weights='imagenet', \n",
    "                                                     include_top=False)\n",
    "global_avg_pooling = GlobalAveragePooling2D()(transfer_resnet_model.output)\n",
    "dropout = Dropout(rate=0.5)(global_avg_pooling)\n",
    "output = Dense(3, activation='softmax')(dropout)\n",
    "tune_resnet_model = Model(inputs=transfer_resnet_model.input, \n",
    "                     outputs=output)\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "tune_resnet_model.compile(loss='categorical_crossentropy', \n",
    "                     optimizer=optimizer, \n",
    "                     metrics=['accuracy', f1_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f88b0-944f-4e31-a933-b50379edeb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', \n",
    "                         mode='min', \n",
    "                         patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a161d4f-8bdf-42af-86aa-a0a2b366d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "tune_resnet_model_fit = tune_resnet_model.fit(train_dataset, \n",
    "                                              epochs=1, \n",
    "                                              validation_data=test_dataset,\n",
    "                                              callbacks=[callback],\n",
    "                                              verbose=1)\n",
    "\n",
    "save_best_model = ModelCheckpoint('best_model.h5', \n",
    "                              monitor='val_loss', \n",
    "                              mode='min', \n",
    "                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879d21f-f2d7-4922-a05b-a42d5db0a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training\n",
    "plot_results(tune_resnet_model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8076ceb-8436-44ef-a67b-360bc148f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "make_predictions(test_dataset, load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c24df-8181-4d50-a0f3-8d3c12b9d9a6",
   "metadata": {},
   "source": [
    "### <ins>5. Recommended Model</ins>\n",
    "\n",
    "Highest F1 scores are from the tuned transfer learning reset model. Since the dataset is imbalanced with a lot more pneumonia than normal than Covid-19 images, F1 is a better metric for performance evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134e815-e3cd-4bdc-b8e0-a61c636ec16c",
   "metadata": {},
   "source": [
    "### <ins>6. Key Findings</ins>\n",
    "\n",
    "The dataset available is imbalanced, accuracy alone would provide a skewed interpretation. So evaluations were made on the F1 metric that balances precision and recall.\n",
    "\n",
    "Simpler VGG16 though performed well with higher F1 scores and may still be applicable if small model size is a criteria especially for local inferences in mobile apps like smart phones, tablets where internet availability is poor in remote areas but diagnosis is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe309d-d220-416c-abc4-166dcb314353",
   "metadata": {},
   "source": [
    "### <ins>7. Next Steps</ins>\n",
    "More Covid-19 images can be added to give a more balanced dataset. More augmentations to the data can be introduced with more complex image manipulations like adding noise and adjusting contrast. Other more advance deep learning models, like Inception and Xception, can explored with transfer learning to reduce training time, especially with more data and augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc86eac-d3b4-4bb6-9bf8-0375d85f4aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "ibm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
